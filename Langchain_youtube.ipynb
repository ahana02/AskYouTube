{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN37sQfYHScXyJdIX98+KZ+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahana02/AskYouTube/blob/main/Langchain_youtube.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Use GPU runtime"
      ],
      "metadata": {
        "id": "MtKoKnp63RqA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyzEXeRkYGIb",
        "outputId": "b5b23e01-1d49-4094-88fe-974b5c7db367"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-15.0.0\n"
          ]
        }
      ],
      "source": [
        "pip install pytube"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install git+https://github.com/openai/whisper.git -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEuh12CQYcyi",
        "outputId": "b448d432-6234-485f-96c0-c39e378dcfcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "import pytube"
      ],
      "metadata": {
        "id": "iqQXWexQYgBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading the taken Youtube link\n",
        "url = \"https://www.youtube.com/watch?v=QDX-1M5Nj7s\"\n",
        "video = pytube.YouTube(url,use_oauth=False,\n",
        "        allow_oauth_cache=True)\n",
        "video.streams.get_highest_resolution().filesize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FUhWKz1Y0HB",
        "outputId": "d449e25f-27ff-41b5-ce04-3c3d32359276"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "93449491"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting and downloading as 'MP4' file\n",
        "audio = video.streams.get_audio_only()\n",
        "fn = audio.download(output_path=\"tmp.mp3\")"
      ],
      "metadata": {
        "id": "CAQzzx3VY6Mp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the 'base' model of Whisper\n",
        "model = whisper.load_model(\"base\")"
      ],
      "metadata": {
        "id": "q-fKBf3PaG4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transcription = model.transcribe(\"/content/tmp.mp3/MIT Introduction to Deep Learning  6S191.mp4\")"
      ],
      "metadata": {
        "id": "YkKvgw6eZ5HW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = transcription['segments']\n",
        "print(res)"
      ],
      "metadata": {
        "id": "6_jyeEqJaRiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdlpSiqyfMxs",
        "outputId": "65249571-e5d2-43e2-8e97-8f03066b8888"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 2,\n",
              " 'seek': 3000,\n",
              " 'start': 31.0,\n",
              " 'end': 37.0,\n",
              " 'text': ' This is a course about justice and we begin with a story.',\n",
              " 'tokens': [50414,\n",
              "  639,\n",
              "  307,\n",
              "  257,\n",
              "  1164,\n",
              "  466,\n",
              "  6118,\n",
              "  293,\n",
              "  321,\n",
              "  1841,\n",
              "  365,\n",
              "  257,\n",
              "  1657,\n",
              "  13,\n",
              "  50714],\n",
              " 'temperature': 0.0,\n",
              " 'avg_logprob': -0.13037579329972415,\n",
              " 'compression_ratio': 1.663716814159292,\n",
              " 'no_speech_prob': 0.6196123957633972}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "def store_segments(segments):\n",
        "  texts = []\n",
        "  start_times = []\n",
        "\n",
        "  for segment in segments:\n",
        "    text = segment['text']\n",
        "    start = segment['start']\n",
        "\n",
        "    # Convert the starting time to a datetime object\n",
        "    start_datetime = datetime.fromtimestamp(start)\n",
        "\n",
        "    # Format the starting time as a string in the format \"00:00:00\"\n",
        "    formatted_start_time = start_datetime.strftime('%H:%M:%S')\n",
        "\n",
        "    texts.append(\"\".join(text))\n",
        "    start_times.append(formatted_start_time)\n",
        "\n",
        "  return texts, start_times"
      ],
      "metadata": {
        "id": "G43zeNwUiSkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_segments(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaqzfco_iVOr",
        "outputId": "7cb366e7-66a3-4a59-ef9a-b6dd871fd7ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([' Good afternoon, everyone. Thank you all for joining today. My name is Alexander Amini,',\n",
              "  \" and I'll be one of your course organizers this year, along with Ava. And together, we're\",\n",
              "  ' super excited to introduce you all to Introduction to Deep Learning. Now, MIT Inter to Deep Learning',\n",
              "  ' is a really, really fun, exciting and fast-paced program here at MIT. And let me start by just',\n",
              "  \" first of all, giving you a little bit of background into what we do and what you're going to\",\n",
              "  \" learn about this year. So this week of Introduction to Deep Learning, we're going to cover a ton\",\n",
              "  \" of material in just one week. You'll learn the foundations of this really, really fascinating\",\n",
              "  \" and exciting field of deep learning and artificial intelligence. And more importantly, you're\",\n",
              "  ' going to get hands-on experience actually reinforcing what you learn in the lectures as part of',\n",
              "  ' hands-on software labs. Now, over the past decade, AI and deep learning have really had a huge',\n",
              "  ' resurgence and had incredible successes. And a lot of problems that even just a decade ago, we',\n",
              "  \" thought we're not really even solvable in the near future. Now, we're solving with deep learning\",\n",
              "  ' with incredible ease. Now, this past year in particular of 2022 has been an incredible year for',\n",
              "  \" deep learning progress. And I'd like to say that actually this past year in particular has been the\",\n",
              "  ' year of generative deep learning, using deep learning to generate brand new types of data that',\n",
              "  ' have never been seen before and never existed in reality. In fact, I want to start this class by',\n",
              "  ' actually showing you how we started this class several years ago, which was by playing this video',\n",
              "  \" that I'll play in a second. Now, this video actually was an introductory video for the class. It was\",\n",
              "  \" and kind of exemplifies this idea that I'm talking about. So let me just start there and play\",\n",
              "  ' this video first of all. Hi everybody and welcome to MIT, six S-191. We are',\n",
              "  \" conducting course on deep learning to talk here at MIT. We've learned to revolutionize\",\n",
              "  \" things so many things from the bodies, the medicine and everything in the field. You'll learn\",\n",
              "  ' upon the levels of this field and how you can build some of these incredible alternatives.',\n",
              "  \" In fact, this is where our students and video are not real and we're created to be deep learning\",\n",
              "  \" and our visual intelligence. And in this class, you'll learn how to have been honored\",\n",
              "  \" with me today and I hope to be in the way that we're seeing.\",\n",
              "  \" So in case you couldn't tell, this video and its entire audio was actually not real. It was\",\n",
              "  ' synthetically generated by a deep learning algorithm and when we introduced this class a few years',\n",
              "  ' ago, this video was created several years ago. But even several years ago,',\n",
              "  ' when we introduced this and put it on YouTube, when some were viral, people really loved this',\n",
              "  ' video. They were intrigued by how real the video and audio felt and looked entirely generated by',\n",
              "  ' an algorithm, by a computer. And people were shocked with the power and the realism of these',\n",
              "  ' types of approaches and this was a few years ago. Now, fast forward to today and the state of deep',\n",
              "  \" learning today, we have seen deep learning accelerating at a rate faster than we've ever seen\",\n",
              "  ' before. In fact, we can use deep learning now to generate not just images of faces, but generate',\n",
              "  ' full synthetic environments where we can train autonomous vehicles entirely in simulation and',\n",
              "  ' deploy them on full scale vehicles in the real world seamlessly. The videos here you see are',\n",
              "  ' actually from a data driven simulator from neural networks generated called Vista that we actually',\n",
              "  ' built here at MIT and have open sourced to the public. So all of you can actually train and build',\n",
              "  ' the future of autonomy and self-driving cars. And of course, it goes far beyond this as well.',\n",
              "  ' Deep learning can be used to generate content directly from how we speak and the language that',\n",
              "  ' we convey to it from prompts that we say. Deep learning can reason about the prompts in natural',\n",
              "  ' language and English, for example, and then guide and control what is generated according to what',\n",
              "  \" we specify. We've seen examples of where we can generate, for example, things that, again,\",\n",
              "  ' have never existed in reality. We can ask a neural network to generate a photo of an astronaut',\n",
              "  ' writing a horse. And it actually can imagine, hallucinate what this might look like even though,',\n",
              "  \" of course, this photo, not only this photo has never occurred before, but I don't think any photo\",\n",
              "  \" of an astronaut writing a horse has ever occurred before. So there's not really even training data\",\n",
              "  ' that you could go off in this case. And my personal favorite is actually how we can not only build',\n",
              "  ' software that can generate images and videos, but build software that can generate software',\n",
              "  ' as well. We can also have algorithms that can take language prompts, for example, a prompt like',\n",
              "  ' this, write code and TensorFlow to generate or to train a neural network. And not only will it',\n",
              "  ' write the code and create that neural network, but it will have the ability to reason about the',\n",
              "  \" code that it's generated and walk you through. Step by step, explaining the process and procedure\",\n",
              "  ' all the way from the ground up to you so that you can actually learn how to do this process as well.',\n",
              "  ' Now, I think some of these examples really just highlight how far deep learning and these',\n",
              "  ' methods have come in the past six years since we started this course. And you saw that example',\n",
              "  \" just a few years ago from that introductory video. But now we're seeing such incredible advances.\",\n",
              "  ' The most amazing part of this course, in my opinion, is actually that within this one week,',\n",
              "  \" we're going to take you through from the ground up, starting from today, all of the foundational\",\n",
              "  ' building blocks that will allow you to understand and make all of this amazing advances possible.',\n",
              "  \" So with that, hopefully now you're all super excited about what this class will teach. And I want to\",\n",
              "  \" basically now just start by taking a step back and introducing some of these terminologies that I've\",\n",
              "  ' kind of been throwing around so far, the deep learning, artificial intelligence, what do these',\n",
              "  ' things actually mean? So first of all, I want to maybe just take a second to speak a little bit',\n",
              "  ' about intelligence and what intelligence means at its core. So to me, intelligence is simply the',\n",
              "  ' ability to process information such that we can use it to inform some future decision or action',\n",
              "  ' that we take. Now, the field of artificial intelligence is simply the ability for us to build',\n",
              "  ' algorithms, artificial algorithms that can do exactly this, process information to inform some',\n",
              "  ' future decision. Now, machine learning is simply a subset of AI, which focuses specifically on how',\n",
              "  ' we can build a machine to or teach a machine how to do this from some experiences or data, for',\n",
              "  ' example. Now, deep learning goes one step beyond this and is a subset of machine learning, which',\n",
              "  ' focuses explicitly on what are called neural networks and how we can build neural networks that',\n",
              "  ' can extract features in the data. These are basically what you can think of as patterns that',\n",
              "  \" occur within the data so that it can learn to complete these tasks as well. Now, that's exactly what\",\n",
              "  \" this class is really all about at its core. We're going to try and teach you and give you the\",\n",
              "  ' foundational understanding and how we can build and teach computers to learn tasks, many different',\n",
              "  \" types of tasks directly from raw data. And that's really what this class boils down to at its\",\n",
              "  \" most simple form. And we'll provide a very solid foundation for you both on the technical side\",\n",
              "  ' through the lectures, which will happen in two parts throughout the class, the first lecture and',\n",
              "  ' the second lecture, each one about one hour long, followed by a software lab, which will immediately',\n",
              "  ' follow the lectures, which will try to reinforce a lot of what we cover in the technical part of',\n",
              "  ' the class and give you hands-on experience implementing those ideas. So this program is split between',\n",
              "  ' these two pieces, the technical lectures and the software labs. We have several new updates this',\n",
              "  ' year in specific, especially in many of the later lectures. The first lecture will cover the foundations',\n",
              "  \" of deep learning, which is going to be right now. And finally, we'll conclude the course with some\",\n",
              "  ' very exciting guest lectures from both academia and industry who are really leading and driving',\n",
              "  ' forward the state of AI and deep learning. And of course, we have many awesome prizes that go with',\n",
              "  ' all of the software labs and the project competition at the end of the course. So maybe quickly to go',\n",
              "  \" through these each day, like I said, we'll have dedicated software labs that couple with the lectures.\",\n",
              "  \" Starting today with Lab 1, you'll actually build a neural network, keeping with the theme of\",\n",
              "  \" generative AI, you'll build a neural network that can learn, listen to a lot of music and actually\",\n",
              "  ' learn how to generate brand new songs in that genre of music. At the end, at the next level of the',\n",
              "  \" class on Friday, we'll host a project pitch competition where either you individually or as part of\",\n",
              "  \" a group can participate and present an idea, a novel deep learning idea to all of us. It'll be\",\n",
              "  ' roughly three minutes in length. And we will focus not as much because this is a one week program.',\n",
              "  ' We are not going to focus so much on the results of your pitch, but rather the invasion and the idea',\n",
              "  \" and the novelty of what you're trying to propose. The prizes here are quite significant already.\",\n",
              "  ' Where first prize is going to get an Nvidia GPU, which is really a key piece of hardware that is',\n",
              "  ' instrumental. If you want to actually build a deep learning project and train these neural',\n",
              "  ' networks, which can be very large and require a lot of compute, these prizes will give you the compute',\n",
              "  \" to do so. And finally, this year we'll be awarding a grand prize for labs two and three combined,\",\n",
              "  ' which will occur on Tuesday and Wednesday, focused on what I believe is actually solving some of the',\n",
              "  ' most exciting problems in this field of deep learning and how specifically how we can build models',\n",
              "  \" that can be robust, not only accurate, but robust and trustworthy and safe when they're deployed\",\n",
              "  \" as well. And you'll actually get experience developing those types of solutions that can actually\",\n",
              "  ' advance the state of the art and AI. Now, all of these labs that I mentioned and competitions here',\n",
              "  \" are going to be due on Thursday night at 11 p.m. right before the last day of class. And we'll be\",\n",
              "  ' helping you all along the way. This prize or this competition in particular has very significant',\n",
              "  ' prizes. So I encourage all of you to really enter this prize and try to try to give a chance to win',\n",
              "  \" the prize. And of course, like I said, we're going to be helping you all along the way who are\",\n",
              "  ' many available resources throughout this class to help you achieve this. Please post a Piazza if',\n",
              "  ' you have any questions. And of course, this program has an incredible team that you can reach out to',\n",
              "  ' at any point in case you have any issues or questions on the materials. Myself and Ava will be your',\n",
              "  \" two main lectures for the first part of the class. We'll also be hearing, like I said, in the\",\n",
              "  ' later part of the class from some guest lectures who will share some really cutting-edge state-of-the-art',\n",
              "  ' developments and deep learning. And of course, I want to give a huge shout out and thanks to all of',\n",
              "  \" our sponsors who without their support, this program wouldn't have been possible for yet again\",\n",
              "  \" another year. So thank you all. Okay, so now with that, let's really dive into the really fun stuff\",\n",
              "  \" of today's lecture, which is, you know, the technical part. And I think I want to start this part by\",\n",
              "  ' asking all of you and having yourselves ask yourself, you know, having you ask yourselves this',\n",
              "  ' question of, you know, why are all of you here, first of all, why do you care about this topic',\n",
              "  ' in the first place? Now, I think to answer this question, we have to take a step back and think',\n",
              "  ' about, you know, the history of machine learning and what machine learning is and what deep learning',\n",
              "  ' brings to the table on top of machine learning. Now, traditional machine learning algorithms',\n",
              "  ' typically define what are called these set of features in the data. You can think of these as',\n",
              "  ' certain patterns in the data and usually these features are hand engineered. So probably a human',\n",
              "  ' will come into the data set and with a lot of domain knowledge and experience can try to uncover',\n",
              "  ' what these features might be. Now, the key idea of deep learning and this is really central to this',\n",
              "  ' class is that instead of having a human define these features, what if we could have a machine',\n",
              "  ' look at all of this data and actually try to extract and uncover what are the core patterns in',\n",
              "  ' the data so that it can use those when it sees new data to make some decisions. So, for example,',\n",
              "  ' if we wanted to detect faces in an image, a deep neural network algorithm might actually learn',\n",
              "  ' that in order to detect a face, it first has to detect things like edges in the image, lines and',\n",
              "  ' edges. And when you combine those lines and edges, you can actually create compositions of features',\n",
              "  ' like corners and curves, which when you combine those, you can create more high level features,',\n",
              "  ' for example, eyes and noses and ears. And then those are the features that allow you to ultimately',\n",
              "  ' detect what you care about detecting, which is the face. But all of these come from what are called',\n",
              "  ' kind of a hierarchical learning of features. And you can actually see some examples of these.',\n",
              "  \" These are real features learned by a neural network and how they're combined defines this progression\",\n",
              "  ' of information. But in fact, what I just described, this underlying and fundamental building block',\n",
              "  ' of neural networks and deep learning have actually existed for decades. Now, why are we studying',\n",
              "  ' all of this now and today in this class with all this great enthusiasm to learn this, right? Well,',\n",
              "  ' for one, there have been several key advances that have occurred in the past decade. Number one is',\n",
              "  ' that data is so much more pervasive than it has ever been before in our lifetimes. These models',\n",
              "  \" are hungry for more data. And we're living in the age of big data. More data is available to these\",\n",
              "  ' models than ever before and they thrive off of that. Secondly, these algorithms are massively',\n",
              "  \" parallelizable. They require a lot of compute. And we're also at a unique time in history where we\",\n",
              "  ' have the ability to train these extremely large scale algorithms and techniques that have existed',\n",
              "  ' for a very long time. But we can now train them due to the hardware advances that have been made.',\n",
              "  ' And finally, due to open source toolboxes and software platforms like TensorFlow, for example,',\n",
              "  ' which all of you will get a lot of experience on in this class, training and building the code',\n",
              "  ' for these neural networks has never been easier. So from the software point of view as well,',\n",
              "  \" there have been incredible advances to open source the underlying fundamentals of what you're going\",\n",
              "  ' to learn. So let me start now with just building up from the ground up, the fundamental building block',\n",
              "  \" of every single neural network that you're going to learn in this class. And that's going to be\",\n",
              "  ' just a single neuron. And in neural network language, a single neuron is called a perceptron.',\n",
              "  \" So what is a perceptron? A perceptron is, like I said, a single neuron. And it's actually, I'm going\",\n",
              "  \" to say it's very, very simple idea. So I want to make sure that everyone in the audience understands\",\n",
              "  \" exactly what a perceptron is and how it works. So let's start by first defining a perceptron as taking\",\n",
              "  ' as input a set of inputs. So on the left hand side, you can see this perceptron takes M different',\n",
              "  \" inputs, 1 to M. These are the blue circles. We're denoting these inputs as x's.\",\n",
              "  ' Each of these numbers, each of these inputs, is then multiplied by a corresponding weight,',\n",
              "  \" which we can call w. So x1 will be multiplied by w1. And we'll add the result of all of these\",\n",
              "  ' multiplications together. Now we take that single number after the addition and we pass it through',\n",
              "  ' this nonlinear, what we call a nonlinear activation function. And that produces our final output',\n",
              "  ' of the perceptron, which we can call y. Now this is actually not entirely accurate of the',\n",
              "  \" picture of a perceptron. There's one step that I forgot to mention here. So in addition to\",\n",
              "  \" multiplying all of these inputs with their corresponding weights, we're also now going to add\",\n",
              "  \" what's called a bias term. Here denoted as this w0, which is just a scalar weight. And you can\",\n",
              "  \" think of it coming with an input of just 1. So that's going to allow the network to basically shift\",\n",
              "  ' its nonlinear activation function nonlinearly as it sees its inputs.',\n",
              "  ' Now on the right hand side, you can see this diagram mathematically formulated. As a single',\n",
              "  ' equation, we can now rewrite this linear this equation with linear algebra terms of vectors',\n",
              "  ' and dot products. So for example, we can define our entire inputs x1 to xm as large vector x.',\n",
              "  ' That large vector x can be multiplied by or take you a dot, excuse me, matrix multiplied',\n",
              "  ' with our weights w. This again, another vector of our weights w1 to wm.',\n",
              "  ' Taking their dot product not only multiplies them, but it also adds the resulting terms together.',\n",
              "  ' Adding a bias, like we said before, and applying this nonlinearity.',\n",
              "  \" Now you might be wondering what is this nonlinear function? I've mentioned it a few times already.\",\n",
              "  ' Well, I said it is a function that we pass the outputs of the neural network through before we',\n",
              "  \" return it to the next neuron in the pipeline. So one common example of a nonlinear function that's\",\n",
              "  ' very popular in deep neural networks is called the sigmoid function. You can think of this as kind',\n",
              "  ' of a continuous version of a threshold function. It goes from 0 to 1 and it can take us input any',\n",
              "  ' real number on the real number line. And you can see an example of it illustrated on the bottom',\n",
              "  ' right hand. Now, in fact, there are many types of nonlinear activation functions that are popular',\n",
              "  \" in deep neural networks. And here are some common ones. And throughout this presentation, you'll\",\n",
              "  \" actually see some examples of these code snippets on the bottom of the slides where we'll try and\",\n",
              "  \" actually tie in some of what you're learning in the lectures to actual software and how you can\",\n",
              "  ' implement these pieces, which will help you a lot for your software labs explicitly. So the sigmoid',\n",
              "  \" activation on the left is very popular since it's a function that outputs between 0 and 1. So\",\n",
              "  ' especially when you want to deal with probability distributions, for example, this is very important',\n",
              "  ' because probabilities live between 0 and 1. In modern deep neural networks, though, the',\n",
              "  ' relu function, which you can see on the far right hand, is a very popular activation function',\n",
              "  \" because it's piecewise linear. It's extremely efficient to compute, especially when\",\n",
              "  \" computing it's derivatives, right? It's derivatives are constants, except for nonlinear, yet 0.\",\n",
              "  ' Now, I hope actually all of you are probably asking this question to yourself of why do we even',\n",
              "  ' need this nonlinear activation function? It seems like it kind of just complicates this whole',\n",
              "  \" picture when we didn't really need it in the first place. And I want to just spend a moment\",\n",
              "  ' on answering this because the point of a nonlinear activation function is, of course, number one is',\n",
              "  ' to introduce nonlinearities to our data, right? If we think about our data, almost all data that we',\n",
              "  ' care about, all real world data is highly nonlinear. Now, this is important because if we want to be',\n",
              "  ' able to deal with those types of data sets, we need models that are also nonlinear so they can capture',\n",
              "  ' those same types of patterns. So imagine I told you to separate, for example, I gave you this',\n",
              "  ' data set, red points from green points and I asked you to try and separate those two types of',\n",
              "  ' data points. Now, you might think that this is easy, but what if I could only, if I told you,',\n",
              "  ' that you could only use a single line to do so? Well, now it becomes a very complicated problem.',\n",
              "  \" In fact, you can't really solve it effectively with a single line. And in fact, if you introduce\",\n",
              "  \" nonlinear activation functions to your solution, that's exactly what allows you to, you know,\",\n",
              "  ' deal with these types of problems. Nonlinear activation functions allow you to deal with',\n",
              "  \" nonlinear types of data. Now, and that's what exactly makes neural networks so powerful at their core.\",\n",
              "  \" So let's understand this maybe with a very simple example, walking through this diagram of a\",\n",
              "  ' perceptron one more time. Imagine I give you this trained neural network with weights now, not',\n",
              "  \" W1, W2. I'm going to actually give you numbers at these locations, right? So the trained weights,\",\n",
              "  ' W0 will be 1 and W will be a vector of 3 and negative 2. So this neural network has two inputs,',\n",
              "  ' like we said before, it has input x1 and has input x2. If we want to get the output of it,',\n",
              "  ' this is also the main thing I want all of you to take away from this lecture today is that',\n",
              "  ' to get the output of a perceptron, there are three steps we need to take, right? From this stage,',\n",
              "  ' we first compute the multiplication of our inputs with our weights.',\n",
              "  \" Sorry, yeah, multiply them together, add their result and compute a nonlinearity. It's these three\",\n",
              "  ' steps that define the forward propagation of information through a perceptron.',\n",
              "  \" So let's take a look at how that exactly works, right? So if we plug in these numbers to those\",\n",
              "  ' equations, we can see that everything inside of our nonlinearity, here the nonlinearity is G,',\n",
              "  ' right? That function G, which could be a sigmoid, we saw a previous slide. That component inside',\n",
              "  ' our nonlinearity is in fact just a two-dimensional line. It has two inputs, and if we consider the',\n",
              "  ' space of all of the possible inputs that this neural network could see, we can actually plot this',\n",
              "  ' on a decision boundary, right? We can plot this two-dimensional line as a decision boundary,',\n",
              "  ' as a plane separating these two components of our space. In fact, not only is it a single plane,',\n",
              "  \" there's a directionality component, depending on which side of the plane that we live on.\",\n",
              "  ' If we see an input, for example, here, negative one, two, we actually know that it lives on one',\n",
              "  ' side of the plane, and it will have a certain type of output. In this case, that output is going to be',\n",
              "  ' positive, right? Because in this case, when we plug those components into our equation,',\n",
              "  \" we'll get a positive number that passes through the nonlinearity component, and that gets propagated\",\n",
              "  \" through as well. Of course, if you're on the other side of the space, you're going to have the\",\n",
              "  ' opposite result, right? That thresholding function is going to essentially live at this decision',\n",
              "  ' boundary. Depending on which side of the space you live on, that thresholding function, that',\n",
              "  ' sigmoid function, is going to then control how you move to one side or the other.',\n",
              "  ' Now, in this particular example, this is very convenient, because we can actually visualize,',\n",
              "  \" and I can draw this exact full space for you on this slide. It's only a two-dimensional space,\",\n",
              "  \" so it's very easy for us to visualize. But, of course, for almost all problems that we care about,\",\n",
              "  ' our data points are not going to be two-dimensional. If you think about an image,',\n",
              "  ' the dimensionality of an image is going to be the number of pixels that you have in the image.',\n",
              "  ' So these are going to be thousands of dimensions, millions of dimensions, or even more.',\n",
              "  \" And then, drawing these types of plots, like you see here, is simply not feasible. We can't always\",\n",
              "  ' do this, but hopefully this gives you some intuition to understand, kind of, as we build up into',\n",
              "  \" more complex models. So now that we have an idea of the perceptron, let's see how we can actually\",\n",
              "  ' take this single neuron and start to build it up into something more complicated, a full neural',\n",
              "  \" network, and build a model from that. So let's revisit, again, this previous diagram of the perceptron.\",\n",
              "  ' If, again, just to reiterate one more time, this core piece of information that I want all of',\n",
              "  ' you to take away from this class is how a perceptron works and how it propagates information to',\n",
              "  ' its decision. There are three steps. First is the dot product, second is the bias, and third is',\n",
              "  ' the non-miniarity. And you keep repeating this process for every single perceptron in your neural',\n",
              "  \" network. Let's simplify the diagram a little bit. I'll get rid of the weights. And you can assume that\",\n",
              "  \" every line here, now basically has an associated weight scalar that's associated with it. Every line\",\n",
              "  \" also has, it corresponds to the input that's coming in. It has a weight that's coming in also at\",\n",
              "  \" on the line itself. And I've also removed the bias just for sake of simplicity, but it's still there.\",\n",
              "  \" So now the result is that Z, which let's call that the result of our dot product plus the bias,\",\n",
              "  \" is going, and that's what we pass into our non-linear function, that piece is going to be applied\",\n",
              "  ' to that activation function. Now the final output here is simply going to be G, which is our',\n",
              "  ' activation function of Z, right? Z is going to be basically what you can think of the state of',\n",
              "  \" this neuron. It's the result of that dot product plus bias. Now if we want to define and build up\",\n",
              "  ' a multi-layered output neural network, if we want two outputs to this function, for example,',\n",
              "  \" it's a very simple procedure. We just have now two neurons, two perceptrons. Each perceptron\",\n",
              "  ' will control the output for its associated piece, right? So now we have two outputs. Each one is a',\n",
              "  ' normal perceptron. It takes all of the inputs, so they both take the same inputs, but amazingly,',\n",
              "  ' now with this mathematical understanding, we can start to build our first neural network entirely',\n",
              "  ' from scratch. So what does that look like? So we can start by firstly initializing these two',\n",
              "  ' components. The first component that we saw was the weight matrix, excuse me, the weight vector.',\n",
              "  \" It's a vector of weights, in this case. And the second component is the bias vector that we're\",\n",
              "  ' going to multiply with the dot product of all of our inputs by our weights, right? So the only',\n",
              "  \" remaining step now after we've defined these parameters of our layer is to now define, you know,\",\n",
              "  \" how this forward propagation of information works. And that's exactly those three main components\",\n",
              "  \" that I've been stressing to you. So we can create this call function to do exactly that, to define\",\n",
              "  \" this forward propagation of information. And the story here is exactly the same as we've been\",\n",
              "  ' seeing it, right? Matrix multiply our inputs with our weights, right? Add a bias and then apply a',\n",
              "  ' non-linearity and return the result, right? And that literally, this code will run. This will define',\n",
              "  ' a full neural network layer that you can then take like this. And of course, actually,',\n",
              "  \" luckily for all of you, all of that code, which wasn't much code, that's been abstracted away by\",\n",
              "  ' these libraries like TensorFlow, you can simply call functions like this, which will actually,',\n",
              "  \" you know, replicate exactly that piece of code. So you don't need to necessarily copy all of that\",\n",
              "  ' code down. You just, you can just call it. And with that understanding, you know, we just saw',\n",
              "  ' how you could build a single layer. But of course, now you can actually start to think about how you',\n",
              "  ' can stack these layers as well. So since we now have this transformation, essentially, from our inputs,',\n",
              "  ' to a hidden output, you can think of this as basically how we can define some way of transforming',\n",
              "  ' those inputs, right, into some new dimensional space, right? Perhaps closer to the value that we',\n",
              "  ' want to predict. And that transformation is going to be eventually learned to know how to transform',\n",
              "  \" those inputs into our desired outputs. And we'll get to that later. But for now, the piece that I want\",\n",
              "  ' to really focus on is if we have these more complex neural networks, I want to really distill down',\n",
              "  \" that this is nothing more complex than what we've already seen. If we focus on just one neuron in\",\n",
              "  \" this diagram, take a, here, for example, Z2, right? Z2 is this neuron that's highlighted in the\",\n",
              "  \" middle layer. It's just the same perceptron that we've been seeing so far in this class. It was\",\n",
              "  \" it's output is obtained by taking a dot product, adding a bias, and then applying that non-linearity\",\n",
              "  ' between all of its inputs. If we look at a different node, for example, Z3, which is the one right below',\n",
              "  \" it, it's the exact same story again. It sees all the same inputs, but it has a different set of\",\n",
              "  \" weight matrix that it's going to apply to those inputs. So we'll have a different output. But the\",\n",
              "  \" mathematically equations are exactly the same. So from now on, I'm just going to kind of simplify\",\n",
              "  ' all of these lines and diagrams just to show these icons in the middle just to demonstrate that',\n",
              "  ' these means everything is going to fully connect it to everything and defined by those mathematical',\n",
              "  \" equations that we've been covering. But there's no extra complexity in these models from what you've\",\n",
              "  ' already seen. Now, if you want to stack these types of solutions on top of each other, these',\n",
              "  ' layers on top of each other, you can not only define one layer very easily, but you can actually',\n",
              "  ' create what are called sequential models. These sequential models, you can define one layer after',\n",
              "  ' another, and they define basically the forward propagation of information, not just from the neuron',\n",
              "  ' level, but now from the layer level. Every layer will be fully connected to the next layer,',\n",
              "  ' and the inputs of the secondary layer will be all of the outputs of the prior layer.',\n",
              "  ' Now, of course, if you want to create a very deep neural network, all the deep neural network is,',\n",
              "  \" is we just keep stacking these layers on top of each other. There's nothing else to this story.\",\n",
              "  \" That's really as simple as it is. Once, so these layers are basically all they are, it's just layers\",\n",
              "  ' where the final output is computed, right, by going deeper and deeper into this progression',\n",
              "  ' of different layers, right, and you just keep stacking them until you get to the last layer,',\n",
              "  \" which is your output layer. It's your final prediction that you want to output.\",\n",
              "  ' Right, we can create a deep neural network to do all of this by stacking these layers and',\n",
              "  \" creating these more hierarchical models, like we saw very early in the beginning of today's lecture.\",\n",
              "  ' One where the final output is really computed by, you know, just going deeper and deeper into this',\n",
              "  \" system. Okay, so that's awesome. So we've now seen how we can go from a single neuron\",\n",
              "  ' to a layer to all the way to a deep neural network, right, building off of these foundational',\n",
              "  \" principles. Let's take a look at how exactly we can use these, you know, principles that we've\",\n",
              "  ' just discussed to solve a very real problem that I think all of you are probably very concerned about',\n",
              "  ' this morning when you when you woke up. So that problem is how we can build a neural network',\n",
              "  ' to answer this question, which is, will I pass this class and if I will or will I not?',\n",
              "  \" So to answer this question, let's see if we can train a neural network to solve this problem.\",\n",
              "  \" Okay, so to do this, let's start with a very simple neural network, right, we'll train this model\",\n",
              "  ' with two inputs, just two inputs. One input is going to be the number of lectures that you attend',\n",
              "  ' over the course of this one week. And the second input is going to be how many hours that you spend',\n",
              "  \" on your final project or your competition. Okay, so what we're going to do is firstly go out and\",\n",
              "  \" collect a lot of data from all of the past years that we've taught this course. And we can plot all\",\n",
              "  \" of this data because it's only two input space, we can plot this data on a two-dimensional\",\n",
              "  ' feature space, right. We can actually look at all of the students before you that have passed the',\n",
              "  ' class and failed the class and see where they lived in this space for the amount of hours that they',\n",
              "  \" spent, the number of lectures that they've attended and so on. Green points are the people who have\",\n",
              "  \" passed, read, or those who have failed. Now, and here's you, right, you're right here. Four or\",\n",
              "  \" five is your coordinate space. You fall right there and you've attended four lectures. You've spent\",\n",
              "  ' five hours on your final project. We want to build a neural network to answer the question of,',\n",
              "  \" will you pass the class or will you fail the class? So let's do it. We have two inputs. One is four,\",\n",
              "  \" one is five. These are two numbers. We can feed them through a neural network that we've just seen\",\n",
              "  ' how we can build that. And we feed that into a single layered neural network. Three hidden units',\n",
              "  ' in this example, but we could make it larger if we want it to be more expressive and more powerful.',\n",
              "  \" And we see here that the probability of you passing those classes point one. It's pretty\",\n",
              "  \" physical. So why would this be the case, right? What did we do wrong? Because I don't think it's\",\n",
              "  ' correct, right? When we looked at this space, it looked like actually you were a good candidate to',\n",
              "  \" pass the class. But why is the neural network saying that there's only 10% likelihood that you should pass?\",\n",
              "  ' Does anyone have any ideas? Exactly. So this neural network is just like it was just born,',\n",
              "  \" right? It has no information about the world or this class. It doesn't know what four and five\",\n",
              "  ' mean or what the notion of passing or failing means, right? So exactly right. This neural network has',\n",
              "  \" not been trained. You can think of it kind of as a baby. It hasn't learned anything yet. So our\",\n",
              "  ' job firstly is to train it. And part of that understanding is we first need to tell the neural',\n",
              "  ' network when it makes mistakes, right? So mathematically, we should now think about how we can answer this',\n",
              "  ' question, which is, did my neural network make a mistake? And if it made a mistake, how can I tell',\n",
              "  ' it? How big of a mistake it was so that the next time it sees this data point, can it do better?',\n",
              "  ' Minimize that mistake. So in neural network language, those mistakes are called losses,',\n",
              "  \" and specifically you want to define what's called a loss function, which is going to take as input\",\n",
              "  ' your prediction and the true prediction, right? And how far away your prediction is from the',\n",
              "  \" true prediction tells you how big of a loss there is, right? So for example, let's say we want to build\",\n",
              "  ' a neural network to do classification of, or sorry, actually even before that, I want to maybe give',\n",
              "  ' you some terminology. So there are multiple different ways of saying the same thing in neural networks',\n",
              "  ' and deep learning. So what I just described as a loss function is also commonly referred to as an',\n",
              "  \" objective function in empirical risk, a cost function. These are all exactly the same thing. They're\",\n",
              "  ' all the way for us to train the neural network, to teach the neural network when it makes mistakes.',\n",
              "  ' And what we really ultimately want to do is over the course of an entire data set,',\n",
              "  ' not just one data point of mistakes, we want to say over the entire data set,',\n",
              "  ' we want to minimize all of the mistakes on average that this neural network makes.',\n",
              "  ' So if we look at the problem, like I said, of binary classification, will I pass this class or',\n",
              "  \" will I not? There's a yes or no answer, that means binary classification. Now we can use what's\",\n",
              "  \" called a loss function of the softmax cross entropy loss. And for those of you who aren't familiar,\",\n",
              "  ' this notion of cross entropy is actually developed here at MIT by Shod Klanit. Shod, excuse me, yes.',\n",
              "  ' Claude Shannon, who is a visionary, he did his masters here over 50 years ago, he introduced this',\n",
              "  ' notion of cross entropy and that was pivotal in the ability for us to train these types of neural',\n",
              "  \" networks even now into the future. So let's start by, instead of predicting a binary cross entropy\",\n",
              "  \" output, what if we wanted to predict a final grade of your class score? For example, that's no\",\n",
              "  \" longer binary output, yes or no, it's actually a continuous variable, it's the grade, let's say out\",\n",
              "  ' of 100 points, what is the value of your score in the class project? For this type of loss, we can',\n",
              "  \" use what's called a mean squared error loss. You can think of this literally as just subtracting your\",\n",
              "  \" predicted grade from the true grade and minimizing that distance apart. So I think now we're ready to\",\n",
              "  ' really put all of this information together and tackle this problem of training a neural network,',\n",
              "  ' right, to not just identify how erroneous it is, how large its loss is, but more importantly,',\n",
              "  ' minimize that loss as a function of seeing all of this training data that is observed.',\n",
              "  ' So we know that we want to find this neural network, like we mentioned before, that minimizes',\n",
              "  ' this empirical risk or this empirical loss averaged across our entire data set. Now this means that',\n",
              "  \" we want to find mathematically these W's, right, that minimize J of W. J of W is our loss function,\",\n",
              "  ' averaged over our entire data set, and W is our weight. So we want to find the set of weights',\n",
              "  ' that on average is going to give us the smallest loss as possible. Now remember that W here is just',\n",
              "  \" a list. Basically it's just a group of all of the weights in our neural network. You may have hundreds\",\n",
              "  \" of the weights and a very, very small neural network, or in today's neural networks, you may have\",\n",
              "  ' billions or trillions of weights, and you want to find what is the value of every single one of these',\n",
              "  ' weights that is going to result in the smallest loss as possible. Now how can you do this?',\n",
              "  ' Remember that our loss function, J of W, is just a function of our weights, right? So for any',\n",
              "  ' instantiation of our weights, we can compute a scalar value of how erroneous would our neural',\n",
              "  \" network be for this instantiation of our weights. So let's try and visualize, for example, in a very\",\n",
              "  ' simple example of a two-dimensional space where we have only two weights, extremely simple neural',\n",
              "  ' network here, very small, two-weight neural network, and we want to find what are the optimal weights',\n",
              "  ' that would train this neural network. We can plot basically the loss, how erroneous the neural',\n",
              "  ' network is for every single instantiation of these two weights, right? This is a huge space,',\n",
              "  \" it's an infinite space, but still we can try to, we can have a function that evaluates at every\",\n",
              "  ' point in this space. Now what we ultimately want to do is, again, we want to find which set of',\n",
              "  \" W's will give us the smallest loss possible. That means basically the lowest point on this\",\n",
              "  \" landscape that you can see here, where is the W's that bring us to that lowest point?\",\n",
              "  ' The way that we do this is actually just by firstly starting at a random place, we have no idea',\n",
              "  \" where to start, so pick a random place to start in this space, and let's start there. At this\",\n",
              "  \" location, let's evaluate our neural network. We can compute the loss at this specific location,\",\n",
              "  ' and on top of that we can actually compute how the loss is changing. We can compute the gradient',\n",
              "  ' of the loss because our loss function is a continuous function, right? So we can actually compute',\n",
              "  ' derivatives of our function across the space of our weights, and the gradient tells us the direction',\n",
              "  ' of the highest point, right? So from where we stand, the gradient tells us where we should go',\n",
              "  \" to increase our loss. Now of course we don't want to increase our loss, we want to decrease our loss,\",\n",
              "  ' so we negate our gradient, and we take a step in the opposite direction of the gradient. That brings',\n",
              "  ' us one step closer to the bottom of the landscape, and we just keep repeating this process, right?',\n",
              "  ' Over and over again, we evaluate the neural network at this new location, compute its gradient,',\n",
              "  ' and step in that new direction. We keep traversing this landscape until we converge to the minimum.',\n",
              "  ' We can really summarize this algorithm, which is known formally as gradient descent, right? So',\n",
              "  ' gradient descent simply can be written like this. We initialize all of our weights, right? This can',\n",
              "  ' be two weights, like you saw in the previous example, it can be billions of weights, like in',\n",
              "  ' real neural networks. We compute this gradient of the partial derivative of our loss with respect',\n",
              "  ' to the weights, and then we can update our weights in the opposite direction of this gradient.',\n",
              "  ' So essentially we just take this small amount, small step, you can think of it, which here is denoted',\n",
              "  \" as eta, and we refer to this small step, right? This is commonly referred to as what's known as\",\n",
              "  \" the learning rate. It's like how much we want to trust that gradient and step in the direction of\",\n",
              "  \" that gradient. We'll talk more about this later, but just to give you some sense of code, this algorithm\",\n",
              "  ' is very well translatable to real code as well. For every line on the pseudo code you can see on the',\n",
              "  ' left, you can see corresponding real code on the right that is runnable and directly implementable',\n",
              "  \" by all of you in your labs. But now let's take a look specifically at this term here. This is the\",\n",
              "  ' gradient. We touched very briefly on this in the visual example. This explains, like I said,',\n",
              "  ' how the loss is changing as a function of the weights, right? So as the weights move around,',\n",
              "  ' will my loss increase or decrease, and that will tell the neural network if it needs to move the',\n",
              "  ' weights in a certain direction or not. But I never actually told you how to compute this, right?',\n",
              "  \" And I think that's an extremely important part because if you don't know that, then you can't\",\n",
              "  \" well, you can't train your neural network, right? This is a critical part of training neural networks,\",\n",
              "  \" and that process of computing this line, this gradient line, is known as back propagation. So let's\",\n",
              "  \" do a very quick intro to back propagation and how it works. So again, let's start with the\",\n",
              "  ' simplest neural network in existence. This neural network has one input, one output, and only one',\n",
              "  ' neuron, right? This is as simple as it gets. We want to compute the gradient of our loss with respect',\n",
              "  \" to our weight. In this case, let's compute it with respect to W2, the second weight.\",\n",
              "  ' So this derivative is going to tell us how much a small change in this weight will affect our loss.',\n",
              "  ' If a small change, if we change our weight a little bit in one direction, will it increase our loss',\n",
              "  ' or decrease our loss? So to compute that, we can write out this derivative. We can start with',\n",
              "  ' applying the chain rule backwards from the loss function through the output. Specifically,',\n",
              "  ' what we can do is we can actually just decompose this derivative into two components. The first',\n",
              "  ' component is the derivative of our loss with respect to our output multiplied by the derivative of our',\n",
              "  ' output with respect to W2, right? This is just a standard instantiation of the chain rule with',\n",
              "  \" this original derivative that we had on the left-hand side. Let's suppose we want to compute the\",\n",
              "  ' gradients of the weight before that, which in this case are not W1, but W, excuse me, not W2, but',\n",
              "  ' W1. Well, all we do is replace W2 with W1 and that chain rule still holds, right? That same',\n",
              "  ' equation holds, but now you can see on the red component, that last component of the chain rule,',\n",
              "  \" we have to, once again, recursively apply one more chain rule because that's again another\",\n",
              "  \" derivative that we can't directly evaluate. We can expand that once more with another\",\n",
              "  ' instantiation of the chain rule. Now, all of these components, we can directly propagate these',\n",
              "  \" gradients through the hidden units in our neural network all the way back to the weight that we're\",\n",
              "  ' interested in in this example, right? So we first computed the derivative with respect to W2,',\n",
              "  \" then we can back propagate that and use that information also with W1. That's why we really\",\n",
              "  ' call it back propagation because this process occurs from the output all the way back to the input.',\n",
              "  ' Now, we repeat this process essentially many, many times over the course of training by propagating',\n",
              "  ' these gradients over and over again through the network all the way from the output to the inputs',\n",
              "  ' to determine for every single weight answering this question, which is how much does a small change',\n",
              "  ' in these weights affect our loss function if it increases, it reduces, then how we can use that',\n",
              "  \" improve the loss ultimately because that's our final goal in this class.\",\n",
              "  \" So that's the back propagation algorithm. That's the core of training neural networks. In theory,\",\n",
              "  \" it's very simple. It's really just an instantiation of the chain rule. But let's touch on some insights\",\n",
              "  ' that make training neural networks actually extremely complicated in practice even though the',\n",
              "  ' algorithm of back propagation is simple and many decades old. In practice, though, optimization of',\n",
              "  ' neural networks looks something like this. It looks nothing like that picture that I showed you before.',\n",
              "  ' There are ways that we can visualize very large deep neural networks and you can think of the',\n",
              "  ' landscape of these models looking like something like this. This is an illustration from a paper that',\n",
              "  ' came out several years ago where they tried to actually visualize the landscape of very, very deep',\n",
              "  \" neural networks. That's what this landscape actually looks like. That's what you're trying to\",\n",
              "  ' deal with and find the minimum in this space. You can imagine the challenges that come with that.',\n",
              "  \" To cover the challenges, let's first think of and recall that update equation defined in gradient\",\n",
              "  \" descent. I didn't talk too much about this parameter, ADA, but now let's spend a bit of time\",\n",
              "  ' thinking about this. This is called the learning rate, like we saw before. It determines basically how',\n",
              "  ' big of a step we need to take in the direction of our gradient and every single iteration of',\n",
              "  ' back propagation. In practice, even setting the learning rate can be very challenging. You as',\n",
              "  ' the designer of the neural network have to set this value, this learning rate, and how do you pick',\n",
              "  ' this value? That can actually be quite difficult. It has really large consequences when building a',\n",
              "  \" neural network. For example, if we set the learning rate too low, then we learn very slowly. Let's\",\n",
              "  ' assume we start on the right-hand side here at that initial guess. If our learning rate is not',\n",
              "  \" large enough, not only do we converge slowly, we actually don't even converge to the global\",\n",
              "  ' minimum, because we kind of get stuck in a local minimum. What if we set our learning rate too high?',\n",
              "  ' What can actually happen is we overshoot and we can actually start to diverge from the solution.',\n",
              "  \" The gradients can actually explode. Very bad things happen and then the neural network doesn't\",\n",
              "  \" train. That's also not good. In reality, there's a very happy medium between setting a too small,\",\n",
              "  ' setting a too large, where you set it just large enough to kind of overshoot some of these local',\n",
              "  ' minima, put you into a reasonable part of the search space, where then you can actually converge',\n",
              "  ' on the solutions that you care most about. But actually, how do you set these learning rates in',\n",
              "  ' practice? How do you pick what is the ideal learning rate? One option, and this is actually a very',\n",
              "  ' common option in practices to simply try out a bunch of learning rates and see what works the',\n",
              "  \" best. Let's say a whole grade of different learning rates and train all of these neural networks,\",\n",
              "  ' see which one works the best. But I think we can do something a lot smarter. What are some more',\n",
              "  ' intelligent ways that we could do this instead of exhaustively trying out a whole bunch of different',\n",
              "  ' learning rates? Can we design a learning rate algorithm that actually adapts to our neural network',\n",
              "  \" and adapts to its landscape so that it's a bit more intelligent than that previous idea?\",\n",
              "  ' So this really ultimately means that the learning rate, the speed at which the algorithm is trusting',\n",
              "  ' the gradients that it sees, is going to depend on how large the gradient is in that location',\n",
              "  \" and how fast we're learning. How many other options, and sorry, and many other options that we might\",\n",
              "  \" have as part of training and neural networks, right? So it's not only how quickly we're learning,\",\n",
              "  \" you may judge it on many different factors in the learning landscape. In fact, we've all been\",\n",
              "  \" these different algorithms that I'm talking about, these adaptive learning rate algorithms have been\",\n",
              "  ' very widely studied in practice. There is a very thriving community in the deep learning research',\n",
              "  ' community that focuses on developing and designing new algorithms for learning rate adaptation and',\n",
              "  \" faster optimization of large neural networks like these. And during your labs, you'll actually get the\",\n",
              "  ' opportunity to not only try out a lot of these different adaptive algorithms, which you can see here,',\n",
              "  ' but also try to uncover what are kind of the patterns and benefits of one versus the other. And',\n",
              "  \" that's going to be something that I think you'll find very insightful as part of your labs.\",\n",
              "  \" So another key component of your labs that you'll see is how you can actually put all of this\",\n",
              "  \" information that we've covered today into a single picture that looks roughly something like this,\",\n",
              "  \" which defines your model at the first, at the top here. That's where you define your model,\",\n",
              "  ' where you talked about this in the beginning part of the lecture. For every piece in your model,',\n",
              "  \" you're now going to need to define this optimizer, which we've just talked about. This optimizer is\",\n",
              "  ' defined together with a learning rate, right? How quickly you want to optimize your loss landscape,',\n",
              "  \" and over many loops, you're going to pass over all of the examples in your data set,\",\n",
              "  \" and observe essentially how to improve your network. That's the gradient, and then actually\",\n",
              "  ' improve the network in those directions. And keep doing that over and over and over again,',\n",
              "  ' until eventually your neural network converges to some sort of solution.',\n",
              "  ' So I want to very quickly, briefly, in the remaining time that we have, continue to talk about',\n",
              "  ' tips for training these neural networks in practice, and focus on this very powerful idea of',\n",
              "  ' batching your data into what are called mini batches of smaller pieces of data.',\n",
              "  \" To do this, let's revisit that gradient descent algorithm, right? So here, this gradient that we\",\n",
              "  \" talked about before is actually extraordinarily computationally expensive to compute, because it's\",\n",
              "  ' computed as a summation across all of the pieces in your data set, right? And in most real life,',\n",
              "  \" for real world problems, it's simply not feasible to compute a gradient over your entire data set.\",\n",
              "  ' Data sets are just too large these days. So there are some alternatives, right? What are the',\n",
              "  ' alternatives? Instead of computing the derivative for the gradients across your entire data set,',\n",
              "  ' what if you instead computed the gradient over just a single example in your data set? Just one',\n",
              "  \" example. Well, of course, this estimate of your gradient is going to be exactly that. It's an\",\n",
              "  \" estimate. It's going to be very noisy. It may roughly reflect the trends of your entire data set,\",\n",
              "  \" but because it's a very, it's only one example. In fact, if your entire data set, it may be very noisy.\",\n",
              "  \" Right? Well, the advantage of this, though, is that it's much faster to compute, obviously,\",\n",
              "  \" the gradient over a single example, because it's one example. So computationally, this has huge\",\n",
              "  \" advantages, but the downside is that it's extremely stochastic, right? That's the reason why this\",\n",
              "  \" algorithm is not called gradient descent. It's called stochastic gradient descent. Now,\",\n",
              "  \" now what's the middle ground? Right? Instead of computing it with respect to one example in your\",\n",
              "  \" data set, what if we computed what's called a mini batch of examples, a small batch of examples\",\n",
              "  \" that we can compute the gradients over? And when we take these gradients, they're still computationally\",\n",
              "  \" efficient to compute because it's a mini batch. It's not too large. Maybe we're talking on the order\",\n",
              "  \" of tens or hundreds of examples in our data set, but more importantly, because we've expanded from\",\n",
              "  ' a single example to maybe a hundred examples, the stochasticity is significantly reduced, and the',\n",
              "  \" accuracy of our gradients is much improved. So normally, we're thinking of batch sizes, mini batch\",\n",
              "  ' sizes roughly on the order of 100 data points, tens or hundreds of data points. This is much faster,',\n",
              "  ' obviously, to compute the gradient descent and much more accurate to compute compared to stochastic',\n",
              "  ' gradient descent, which is that single point example. So this increase in gradient accuracy',\n",
              "  ' allows us to essentially converge to our solution much quicker than it could have been possible',\n",
              "  ' in practice due to gradient descent limitations. It also means that we can increase our learning',\n",
              "  \" rate because we can trust each of those gradients much more efficiently. Right? We're now averaging\",\n",
              "  \" over a batch. It's going to be much more accurate than the stochastic version, so we can increase\",\n",
              "  ' that learning rate and actually learn faster as well. This allows us to also massively parallelize',\n",
              "  ' this entire algorithm and computation. Right? We can split up batches onto separate workers and',\n",
              "  ' achieve even more significant speed ups of this entire problem using GPUs. The last topic that I',\n",
              "  \" very, very briefly want to cover in today's lecture is this topic of overfitting. Right? When we\",\n",
              "  \" are optimizing a neural network with stochastic gradient descent, we have this challenge of what's\",\n",
              "  ' called overfitting. Overfitting, I, looks like this roughly, right? So on the left hand side,',\n",
              "  \" we want to build a neural network, or let's say in general, we want to build a machine learning\",\n",
              "  \" model that can accurately describe some patterns in our data, but remember, we're ultimately,\",\n",
              "  \" we don't want to describe the patterns in our training data. Ideally, we want to define the\",\n",
              "  \" patterns in our test data. Of course, we don't observe test data. We only observe training data.\",\n",
              "  ' So we have this challenge of extracting patterns from training data and hoping that they',\n",
              "  ' generalize to our test data. So set in one different way, we want to build models that can learn',\n",
              "  ' representations from our training data that can still generalize even when we show them brand new',\n",
              "  ' unseen pieces of test data. So assume that you want to build a line that can describe or find',\n",
              "  ' the patterns in these points that you can see on the slide. If you have a very simple neural',\n",
              "  ' network, which is just a single line, straight line, you can describe this data sub optimally,',\n",
              "  \" because the data here is nonlinear. You're not going to accurately capture all of the nuances\",\n",
              "  \" and subtleties in this data set. That's on the left hand side. If you move to the right hand side,\",\n",
              "  \" you can see a much more complicated model, but here you're actually overexpressive. You're too\",\n",
              "  \" expressive and you're capturing kind of the nuances, the spurious nuances in your training data\",\n",
              "  ' that are actually not representative of your test data. Ideally, you want to end up with the',\n",
              "  \" model in the middle, which is basically the middle ground, right? It's not too complex and it's not\",\n",
              "  ' too simple. It still gives you what you want to perform well and even when you give it brand new',\n",
              "  \" data. So to address this problem, let's briefly talk about what's called regularization. Regularization\",\n",
              "  ' is a technique that you can introduce to your training pipeline to discourage complex models',\n",
              "  \" from being learned. Now, as we've seen before, this is really critical because neural networks are\",\n",
              "  ' extremely large models. They are extremely prone to overfitting, right? So regularization, having',\n",
              "  ' techniques for regularization has extreme implications towards the success of neural networks and',\n",
              "  ' having them generalize beyond training data far into our testing domain. The most popular',\n",
              "  ' technique for regularization in deep learning is called dropout and the idea of dropout is actually',\n",
              "  \" very simple. It's let's revisit it by drawing this picture of deep neural networks that we saw\",\n",
              "  \" earlier in today's lecture. In dropout, during training, we essentially randomly select some subset\",\n",
              "  ' of the neurons in this neural network and we try to prune them out with some random probability.',\n",
              "  ' So for example, we can select this subset of neurons. We can randomly select them with a probability',\n",
              "  ' of 50 percent and with that probability, we randomly turn them off or on different iterations of',\n",
              "  ' our training. So this is essentially forcing the neural network to learn you can think of an',\n",
              "  \" ensemble of different models. On every iteration, it's going to be exposed to kind of a different\",\n",
              "  ' model internally than the one it had on the last iteration. So it has to learn how to build',\n",
              "  \" internal pathways to process the same information and it can't rely on information that it\",\n",
              "  ' learned on previous iterations. So it forces it to kind of capture some deeper meaning within the',\n",
              "  ' pathways of the neural network and this can be extremely powerful because the number one, it',\n",
              "  \" lowers the capacity of the neural network significantly. You're lowering it by roughly 50 percent\",\n",
              "  ' in this example. But also because it makes it easier to train because the number of weights that',\n",
              "  \" have gradients in this case is also reduced. So it's actually much faster to train them as well.\",\n",
              "  ' Now, like I mentioned, on every iteration, we randomly drop out a different set of neurons,',\n",
              "  ' right? And that helps the data generalize better. And the second regularization techniques,',\n",
              "  ' which is actually a very broad regularization technique far beyond neural networks,',\n",
              "  ' is simply called early stopping. Now, we know the definition of overfitting is simply when our',\n",
              "  \" model starts to represent basically the training data more than the testing data. That's really\",\n",
              "  ' what overfitting comes down to its core. If we set aside some of the training data to use separately,',\n",
              "  \" that we don't train on it, we can use a kind of a testing data set, synthetic testing data set in\",\n",
              "  ' some ways. We can monitor how our network is learning on this unseen portion of data. So for',\n",
              "  ' example, we can over the course of training, we can basically plot the performance of our network',\n",
              "  ' on both the training set as well as our held out test set. And as the network is trained,',\n",
              "  \" we're going to see that, first of all, these both decrease, but there's going to be a point\",\n",
              "  ' where the loss plateaus and starts to increase. The training loss will actually start to increase.',\n",
              "  \" This is exactly the point where you start to overfit, right? Because now you're starting to have,\",\n",
              "  \" sorry, that was the test loss. The test loss actually starts to increase because now you're\",\n",
              "  ' starting to overfit on your training data. This pattern basically continues for the rest of training.',\n",
              "  ' And this is the point that I want you to focus on, right? This middle point is where we need to',\n",
              "  ' stop training because after this point, assuming that this test set is a valid representation',\n",
              "  ' of the true test set, this is the place where the accuracy of the model will only get worse,',\n",
              "  ' right? So this is where we would want to early stop our model and regularize the performance.',\n",
              "  \" And we can see that stopping any time before this point is also not good. We're going to produce\",\n",
              "  \" an underfit model where we could have had a better model on the test data, but it's this tradeoff,\",\n",
              "  \" right? You can't stop too late and you can't stop too early as well.\",\n",
              "  \" So I'll conclude this lecture by just summarizing these three key points that we've covered in\",\n",
              "  \" today's lecture so far. So we first covered these fundamental building blocks of all neural networks,\",\n",
              "  \" which is the single neuron, the perceptron. We've built these up into larger neural layers and then\",\n",
              "  \" from their neural networks and deep neural networks. We've learned how we can train these,\",\n",
              "  \" apply them to data sets, back propagate through them, and we've seen some tips and tricks for\",\n",
              "  \" optimizing these systems end to end. In the next lecture, we'll hear from AVA on deep sequence\",\n",
              "  ' modeling using RNNs and specifically this very exciting new type of model called the transformer',\n",
              "  \" architecture and attention mechanisms. So maybe let's resume the class in about five minutes after\",\n",
              "  ' we have a chance to swap speakers and thank you so much for all of your attention.'],\n",
              " ['00:00:00',\n",
              "  '00:00:14',\n",
              "  '00:00:19',\n",
              "  '00:00:26',\n",
              "  '00:00:32',\n",
              "  '00:00:37',\n",
              "  '00:00:42',\n",
              "  '00:00:47',\n",
              "  '00:00:53',\n",
              "  '00:00:59',\n",
              "  '00:01:05',\n",
              "  '00:01:11',\n",
              "  '00:01:15',\n",
              "  '00:01:23',\n",
              "  '00:01:28',\n",
              "  '00:01:33',\n",
              "  '00:01:39',\n",
              "  '00:01:44',\n",
              "  '00:01:51',\n",
              "  '00:01:56',\n",
              "  '00:02:08',\n",
              "  '00:02:15',\n",
              "  '00:02:24',\n",
              "  '00:02:31',\n",
              "  '00:02:41',\n",
              "  '00:02:50',\n",
              "  '00:02:53',\n",
              "  '00:03:03',\n",
              "  '00:03:08',\n",
              "  '00:03:13',\n",
              "  '00:03:18',\n",
              "  '00:03:26',\n",
              "  '00:03:31',\n",
              "  '00:03:37',\n",
              "  '00:03:45',\n",
              "  '00:03:52',\n",
              "  '00:03:57',\n",
              "  '00:04:02',\n",
              "  '00:04:07',\n",
              "  '00:04:13',\n",
              "  '00:04:18',\n",
              "  '00:04:24',\n",
              "  '00:04:30',\n",
              "  '00:04:36',\n",
              "  '00:04:43',\n",
              "  '00:04:48',\n",
              "  '00:04:54',\n",
              "  '00:04:59',\n",
              "  '00:05:03',\n",
              "  '00:05:08',\n",
              "  '00:05:14',\n",
              "  '00:05:19',\n",
              "  '00:05:25',\n",
              "  '00:05:31',\n",
              "  '00:05:35',\n",
              "  '00:05:41',\n",
              "  '00:05:47',\n",
              "  '00:05:51',\n",
              "  '00:05:56',\n",
              "  '00:06:01',\n",
              "  '00:06:06',\n",
              "  '00:06:13',\n",
              "  '00:06:19',\n",
              "  '00:06:25',\n",
              "  '00:06:29',\n",
              "  '00:06:36',\n",
              "  '00:06:42',\n",
              "  '00:06:48',\n",
              "  '00:06:54',\n",
              "  '00:06:59',\n",
              "  '00:07:05',\n",
              "  '00:07:13',\n",
              "  '00:07:19',\n",
              "  '00:07:23',\n",
              "  '00:07:27',\n",
              "  '00:07:34',\n",
              "  '00:07:38',\n",
              "  '00:07:44',\n",
              "  '00:07:50',\n",
              "  '00:07:56',\n",
              "  '00:08:00',\n",
              "  '00:08:05',\n",
              "  '00:08:11',\n",
              "  '00:08:18',\n",
              "  '00:08:23',\n",
              "  '00:08:29',\n",
              "  '00:08:34',\n",
              "  '00:08:40',\n",
              "  '00:08:47',\n",
              "  '00:08:52',\n",
              "  '00:08:58',\n",
              "  '00:09:03',\n",
              "  '00:09:08',\n",
              "  '00:09:14',\n",
              "  '00:09:20',\n",
              "  '00:09:27',\n",
              "  '00:09:34',\n",
              "  '00:09:39',\n",
              "  '00:09:44',\n",
              "  '00:09:49',\n",
              "  '00:09:54',\n",
              "  '00:09:58',\n",
              "  '00:10:04',\n",
              "  '00:10:08',\n",
              "  '00:10:15',\n",
              "  '00:10:21',\n",
              "  '00:10:25',\n",
              "  '00:10:32',\n",
              "  '00:10:38',\n",
              "  '00:10:44',\n",
              "  '00:10:50',\n",
              "  '00:10:55',\n",
              "  '00:11:01',\n",
              "  '00:11:06',\n",
              "  '00:11:12',\n",
              "  '00:11:17',\n",
              "  '00:11:22',\n",
              "  '00:11:26',\n",
              "  '00:11:31',\n",
              "  '00:11:38',\n",
              "  '00:11:44',\n",
              "  '00:11:50',\n",
              "  '00:11:55',\n",
              "  '00:12:00',\n",
              "  '00:12:05',\n",
              "  '00:12:10',\n",
              "  '00:12:15',\n",
              "  '00:12:20',\n",
              "  '00:12:25',\n",
              "  '00:12:30',\n",
              "  '00:12:36',\n",
              "  '00:12:41',\n",
              "  '00:12:46',\n",
              "  '00:12:52',\n",
              "  '00:12:57',\n",
              "  '00:13:02',\n",
              "  '00:13:08',\n",
              "  '00:13:13',\n",
              "  '00:13:17',\n",
              "  '00:13:22',\n",
              "  '00:13:27',\n",
              "  '00:13:33',\n",
              "  '00:13:39',\n",
              "  '00:13:45',\n",
              "  '00:13:51',\n",
              "  '00:13:57',\n",
              "  '00:14:04',\n",
              "  '00:14:10',\n",
              "  '00:14:16',\n",
              "  '00:14:22',\n",
              "  '00:14:26',\n",
              "  '00:14:31',\n",
              "  '00:14:37',\n",
              "  '00:14:41',\n",
              "  '00:14:47',\n",
              "  '00:14:53',\n",
              "  '00:14:58',\n",
              "  '00:15:04',\n",
              "  '00:15:12',\n",
              "  '00:15:16',\n",
              "  '00:15:23',\n",
              "  '00:15:29',\n",
              "  '00:15:36',\n",
              "  '00:15:42',\n",
              "  '00:15:49',\n",
              "  '00:15:55',\n",
              "  '00:16:00',\n",
              "  '00:16:07',\n",
              "  '00:16:13',\n",
              "  '00:16:17',\n",
              "  '00:16:23',\n",
              "  '00:16:29',\n",
              "  '00:16:36',\n",
              "  '00:16:42',\n",
              "  '00:16:48',\n",
              "  '00:16:57',\n",
              "  '00:17:03',\n",
              "  '00:17:10',\n",
              "  '00:17:16',\n",
              "  '00:17:22',\n",
              "  '00:17:27',\n",
              "  '00:17:34',\n",
              "  '00:17:40',\n",
              "  '00:17:45',\n",
              "  '00:17:52',\n",
              "  '00:17:57',\n",
              "  '00:18:02',\n",
              "  '00:18:06',\n",
              "  '00:18:11',\n",
              "  '00:18:16',\n",
              "  '00:18:21',\n",
              "  '00:18:26',\n",
              "  '00:18:30',\n",
              "  '00:18:35',\n",
              "  '00:18:39',\n",
              "  '00:18:43',\n",
              "  '00:18:51',\n",
              "  '00:18:55',\n",
              "  '00:18:59',\n",
              "  '00:19:04',\n",
              "  '00:19:09',\n",
              "  '00:19:15',\n",
              "  '00:19:21',\n",
              "  '00:19:25',\n",
              "  '00:19:29',\n",
              "  '00:19:33',\n",
              "  '00:19:38',\n",
              "  '00:19:43',\n",
              "  '00:19:49',\n",
              "  '00:19:54',\n",
              "  '00:19:59',\n",
              "  '00:20:06',\n",
              "  '00:20:10',\n",
              "  '00:20:15',\n",
              "  '00:20:21',\n",
              "  '00:20:29',\n",
              "  '00:20:34',\n",
              "  '00:20:38',\n",
              "  '00:20:43',\n",
              "  '00:20:48',\n",
              "  '00:20:55',\n",
              "  '00:21:01',\n",
              "  '00:21:06',\n",
              "  '00:21:12',\n",
              "  '00:21:19',\n",
              "  '00:21:25',\n",
              "  '00:21:31',\n",
              "  '00:21:38',\n",
              "  '00:21:45',\n",
              "  '00:21:49',\n",
              "  '00:21:55',\n",
              "  '00:22:00',\n",
              "  '00:22:05',\n",
              "  '00:22:11',\n",
              "  '00:22:16',\n",
              "  '00:22:21',\n",
              "  '00:22:25',\n",
              "  '00:22:32',\n",
              "  '00:22:37',\n",
              "  '00:22:42',\n",
              "  '00:22:47',\n",
              "  '00:22:52',\n",
              "  '00:22:56',\n",
              "  '00:23:01',\n",
              "  '00:23:07',\n",
              "  '00:23:12',\n",
              "  '00:23:18',\n",
              "  '00:23:22',\n",
              "  '00:23:28',\n",
              "  '00:23:33',\n",
              "  '00:23:39',\n",
              "  '00:23:45',\n",
              "  '00:23:49',\n",
              "  '00:23:56',\n",
              "  '00:24:01',\n",
              "  '00:24:08',\n",
              "  '00:24:14',\n",
              "  '00:24:21',\n",
              "  '00:24:27',\n",
              "  '00:24:34',\n",
              "  '00:24:39',\n",
              "  '00:24:46',\n",
              "  '00:24:51',\n",
              "  '00:24:55',\n",
              "  '00:25:01',\n",
              "  '00:25:07',\n",
              "  '00:25:12',\n",
              "  '00:25:18',\n",
              "  '00:25:23',\n",
              "  '00:25:30',\n",
              "  '00:25:36',\n",
              "  '00:25:42',\n",
              "  '00:25:47',\n",
              "  '00:25:52',\n",
              "  '00:25:57',\n",
              "  '00:26:05',\n",
              "  '00:26:11',\n",
              "  '00:26:18',\n",
              "  '00:26:22',\n",
              "  '00:26:27',\n",
              "  '00:26:32',\n",
              "  '00:26:39',\n",
              "  '00:26:44',\n",
              "  '00:26:51',\n",
              "  '00:26:59',\n",
              "  '00:27:06',\n",
              "  '00:27:11',\n",
              "  '00:27:16',\n",
              "  '00:27:21',\n",
              "  '00:27:26',\n",
              "  '00:27:33',\n",
              "  '00:27:39',\n",
              "  '00:27:44',\n",
              "  '00:27:49',\n",
              "  '00:27:53',\n",
              "  '00:27:58',\n",
              "  '00:28:03',\n",
              "  '00:28:08',\n",
              "  '00:28:13',\n",
              "  '00:28:18',\n",
              "  '00:28:24',\n",
              "  '00:28:28',\n",
              "  '00:28:33',\n",
              "  '00:28:38',\n",
              "  '00:28:43',\n",
              "  '00:28:50',\n",
              "  '00:28:54',\n",
              "  '00:28:58',\n",
              "  '00:29:04',\n",
              "  '00:29:10',\n",
              "  '00:29:14',\n",
              "  '00:29:18',\n",
              "  '00:29:22',\n",
              "  '00:29:27',\n",
              "  '00:29:32',\n",
              "  '00:29:40',\n",
              "  '00:29:45',\n",
              "  '00:29:52',\n",
              "  '00:29:58',\n",
              "  '00:30:04',\n",
              "  '00:30:10',\n",
              "  '00:30:15',\n",
              "  '00:30:20',\n",
              "  '00:30:25',\n",
              "  '00:30:30',\n",
              "  '00:30:37',\n",
              "  '00:30:41',\n",
              "  '00:30:45',\n",
              "  '00:30:50',\n",
              "  '00:30:55',\n",
              "  '00:30:59',\n",
              "  '00:31:05',\n",
              "  '00:31:10',\n",
              "  '00:31:15',\n",
              "  '00:31:21',\n",
              "  '00:31:25',\n",
              "  '00:31:31',\n",
              "  '00:31:36',\n",
              "  '00:31:40',\n",
              "  '00:31:45',\n",
              "  '00:31:50',\n",
              "  '00:31:56',\n",
              "  '00:32:08',\n",
              "  '00:32:14',\n",
              "  '00:32:21',\n",
              "  '00:32:26',\n",
              "  '00:32:31',\n",
              "  '00:32:36',\n",
              "  '00:32:42',\n",
              "  '00:32:47',\n",
              "  '00:32:54',\n",
              "  '00:32:59',\n",
              "  '00:33:05',\n",
              "  '00:33:13',\n",
              "  '00:33:19',\n",
              "  '00:33:25',\n",
              "  '00:33:30',\n",
              "  '00:33:35',\n",
              "  '00:33:41',\n",
              "  '00:33:46',\n",
              "  '00:33:50',\n",
              "  '00:33:56',\n",
              "  '00:34:01',\n",
              "  '00:34:07',\n",
              "  '00:34:12',\n",
              "  '00:34:21',\n",
              "  '00:34:28',\n",
              "  '00:34:35',\n",
              "  '00:34:43',\n",
              "  '00:34:49',\n",
              "  '00:34:54',\n",
              "  '00:35:01',\n",
              "  '00:35:05',\n",
              "  '00:35:14',\n",
              "  '00:35:20',\n",
              "  '00:35:27',\n",
              "  '00:35:32',\n",
              "  '00:35:38',\n",
              "  '00:35:45',\n",
              "  '00:35:53',\n",
              "  '00:35:58',\n",
              "  '00:36:07',\n",
              "  '00:36:13',\n",
              "  '00:36:17',\n",
              "  '00:36:22',\n",
              "  '00:36:27',\n",
              "  '00:36:34',\n",
              "  '00:36:41',\n",
              "  '00:36:47',\n",
              "  '00:36:54',\n",
              "  '00:36:59',\n",
              "  '00:37:06',\n",
              "  '00:37:12',\n",
              "  '00:37:17',\n",
              "  '00:37:25',\n",
              "  '00:37:31',\n",
              "  '00:37:38',\n",
              "  '00:37:44',\n",
              "  '00:37:49',\n",
              "  '00:37:54',\n",
              "  '00:38:00',\n",
              "  '00:38:05',\n",
              "  '00:38:12',\n",
              "  '00:38:18',\n",
              "  '00:38:23',\n",
              "  '00:38:28',\n",
              "  '00:38:34',\n",
              "  '00:38:39',\n",
              "  '00:38:47',\n",
              "  '00:38:52',\n",
              "  '00:38:57',\n",
              "  '00:39:02',\n",
              "  '00:39:10',\n",
              "  '00:39:15',\n",
              "  '00:39:21',\n",
              "  '00:39:29',\n",
              "  '00:39:33',\n",
              "  '00:39:40',\n",
              "  '00:39:44',\n",
              "  '00:39:49',\n",
              "  '00:39:55',\n",
              "  '00:40:00',\n",
              "  '00:40:05',\n",
              "  '00:40:10',\n",
              "  '00:40:15',\n",
              "  '00:40:19',\n",
              "  '00:40:24',\n",
              "  '00:40:30',\n",
              "  '00:40:37',\n",
              "  '00:40:42',\n",
              "  '00:40:48',\n",
              "  '00:40:54',\n",
              "  '00:41:01',\n",
              "  '00:41:05',\n",
              "  '00:41:11',\n",
              "  '00:41:17',\n",
              "  '00:41:22',\n",
              "  '00:41:27',\n",
              "  '00:41:35',\n",
              "  '00:41:41',\n",
              "  '00:41:47',\n",
              "  '00:41:53',\n",
              "  '00:41:59',\n",
              "  '00:42:04',\n",
              "  '00:42:08',\n",
              "  '00:42:14',\n",
              "  '00:42:19',\n",
              "  '00:42:24',\n",
              "  '00:42:28',\n",
              "  '00:42:33',\n",
              "  '00:42:40',\n",
              "  '00:42:45',\n",
              "  '00:42:51',\n",
              "  '00:42:56',\n",
              "  '00:43:02',\n",
              "  '00:43:08',\n",
              "  '00:43:16',\n",
              "  '00:43:21',\n",
              "  '00:43:29',\n",
              "  '00:43:33',\n",
              "  '00:43:38',\n",
              "  '00:43:43',\n",
              "  '00:43:47',\n",
              "  '00:43:51',\n",
              "  '00:43:57',\n",
              "  '00:44:03',\n",
              "  '00:44:09',\n",
              "  '00:44:14',\n",
              "  '00:44:19',\n",
              "  '00:44:25',\n",
              "  '00:44:30',\n",
              "  '00:44:36',\n",
              "  '00:44:44',\n",
              "  '00:44:48',\n",
              "  '00:44:53',\n",
              "  '00:45:00',\n",
              "  '00:45:05',\n",
              "  '00:45:10',\n",
              "  '00:45:15',\n",
              "  '00:45:21',\n",
              "  '00:45:26',\n",
              "  '00:45:31',\n",
              "  '00:45:37',\n",
              "  '00:45:41',\n",
              "  '00:45:47',\n",
              "  '00:45:53',\n",
              "  '00:45:57',\n",
              "  '00:46:03',\n",
              "  '00:46:09',\n",
              "  '00:46:16',\n",
              "  '00:46:23',\n",
              "  '00:46:29',\n",
              "  '00:46:34',\n",
              "  '00:46:41',\n",
              "  '00:46:46',\n",
              "  '00:46:52',\n",
              "  '00:46:59',\n",
              "  '00:47:05',\n",
              "  '00:47:10',\n",
              "  '00:47:15',\n",
              "  '00:47:21',\n",
              "  '00:47:25',\n",
              "  '00:47:30',\n",
              "  '00:47:34',\n",
              "  '00:47:39',\n",
              "  '00:47:44',\n",
              "  '00:47:49',\n",
              "  '00:47:54',\n",
              "  '00:47:59',\n",
              "  '00:48:03',\n",
              "  '00:48:09',\n",
              "  '00:48:14',\n",
              "  '00:48:21',\n",
              "  '00:48:28',\n",
              "  '00:48:33',\n",
              "  '00:48:39',\n",
              "  '00:48:46',\n",
              "  '00:48:52',\n",
              "  '00:48:58',\n",
              "  '00:49:04',\n",
              "  '00:49:10',\n",
              "  '00:49:16',\n",
              "  '00:49:21',\n",
              "  '00:49:27',\n",
              "  '00:49:34',\n",
              "  '00:49:39',\n",
              "  '00:49:44',\n",
              "  '00:49:49',\n",
              "  '00:49:53',\n",
              "  '00:49:59',\n",
              "  '00:50:05',\n",
              "  '00:50:10',\n",
              "  '00:50:18',\n",
              "  '00:50:23',\n",
              "  '00:50:29',\n",
              "  '00:50:35',\n",
              "  '00:50:40',\n",
              "  '00:50:48',\n",
              "  '00:50:53',\n",
              "  '00:50:58',\n",
              "  '00:51:04',\n",
              "  '00:51:08',\n",
              "  '00:51:15',\n",
              "  '00:51:21',\n",
              "  '00:51:28',\n",
              "  '00:51:34',\n",
              "  '00:51:41',\n",
              "  '00:51:47',\n",
              "  '00:51:51',\n",
              "  '00:51:58',\n",
              "  '00:52:02',\n",
              "  '00:52:07',\n",
              "  '00:52:11',\n",
              "  '00:52:17',\n",
              "  '00:52:22',\n",
              "  '00:52:29',\n",
              "  '00:52:34',\n",
              "  '00:52:43',\n",
              "  '00:52:47',\n",
              "  '00:52:52',\n",
              "  '00:52:57',\n",
              "  '00:53:03',\n",
              "  '00:53:09',\n",
              "  '00:53:13',\n",
              "  '00:53:19',\n",
              "  '00:53:25',\n",
              "  '00:53:31',\n",
              "  '00:53:37',\n",
              "  '00:53:43',\n",
              "  '00:53:49',\n",
              "  '00:53:54',\n",
              "  '00:54:00',\n",
              "  '00:54:05',\n",
              "  '00:54:11',\n",
              "  '00:54:18',\n",
              "  '00:54:23',\n",
              "  '00:54:30',\n",
              "  '00:54:37',\n",
              "  '00:54:43',\n",
              "  '00:54:47',\n",
              "  '00:54:53',\n",
              "  '00:54:58',\n",
              "  '00:55:02',\n",
              "  '00:55:08',\n",
              "  '00:55:14',\n",
              "  '00:55:19',\n",
              "  '00:55:26',\n",
              "  '00:55:31',\n",
              "  '00:55:35',\n",
              "  '00:55:43',\n",
              "  '00:55:49',\n",
              "  '00:55:54',\n",
              "  '00:56:01',\n",
              "  '00:56:07',\n",
              "  '00:56:13',\n",
              "  '00:56:18',\n",
              "  '00:56:22',\n",
              "  '00:56:28',\n",
              "  '00:56:33',\n",
              "  '00:56:36',\n",
              "  '00:56:42',\n",
              "  '00:56:47',\n",
              "  '00:56:53',\n",
              "  '00:56:57',\n",
              "  '00:57:02',\n",
              "  '00:57:07',\n",
              "  '00:57:12',\n",
              "  '00:57:17',\n",
              "  '00:57:22',\n",
              "  '00:57:27',\n",
              "  '00:57:34',\n",
              "  '00:57:38',\n",
              "  '00:57:45',\n",
              "  '00:57:51',\n",
              "  '00:57:58',\n",
              "  '00:58:04'])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts, start_times = store_segments(res)"
      ],
      "metadata": {
        "id": "-ZYECiqNgZ8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain"
      ],
      "metadata": {
        "id": "qBBaaahmqCWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai"
      ],
      "metadata": {
        "id": "DLAEaZSYqInM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install faiss-gpu"
      ],
      "metadata": {
        "id": "AbdW-kuUqM2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores.faiss import FAISS\n",
        "from langchain.chains import VectorDBQAWithSourcesChain\n",
        "from langchain import OpenAI\n",
        "import openai\n",
        "import faiss"
      ],
      "metadata": {
        "id": "lqQNXEvAqT62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\""
      ],
      "metadata": {
        "id": "vgN9CeSaqhUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = CharacterTextSplitter(chunk_size=1500, separator=\"\\n\")\n",
        "docs = []\n",
        "metadatas = []\n",
        "for i, d in enumerate(texts):\n",
        "    splits = text_splitter.split_text(d)\n",
        "    docs.extend(splits)\n",
        "    metadatas.extend([{\"source\": start_times[i]}] * len(splits))\n",
        "embeddings = OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "tjMXHVwRqqTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store = FAISS.from_texts(docs, embeddings, metadatas=metadatas)\n",
        "faiss.write_index(store.index, \"docs.index\")"
      ],
      "metadata": {
        "id": "iFri6vBTqutR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQAWithSourcesChain"
      ],
      "metadata": {
        "id": "bUOIpXCFYg_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = VectorDBQAWithSourcesChain.from_llm(llm=OpenAI(temperature=0.9), vectorstore=store)"
      ],
      "metadata": {
        "id": "dZObHNoxqx5A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "890b4648-f59c-468a-d7aa-a30224ff1ebe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/qa_with_sources/vector_db.py:67: UserWarning: `VectorDBQAWithSourcesChain` is deprecated - please use `from langchain.chains import RetrievalQAWithSourcesChain`\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = chain({\"question\": \"What is Backpropagation?\"})"
      ],
      "metadata": {
        "id": "j9i9whWUYlJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Answer: {result['answer']}  Sources: {result['sources']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tKd-k8aa_xZ",
        "outputId": "70718e65-e99c-466f-edc4-89f56e2fbcd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer:  Backpropagation is an algorithm used for training neural networks by propagating errors from the output back to the input.\n",
            "  Sources: 00:42:28, 00:43:02, 00:43:21\n"
          ]
        }
      ]
    }
  ]
}