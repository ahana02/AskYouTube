{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN37sQfYHScXyJdIX98+KZ+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahana02/AskYouTube/blob/main/Langchain_youtube.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Use GPU runtime"
      ],
      "metadata": {
        "id": "MtKoKnp63RqA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyzEXeRkYGIb",
        "outputId": "02600596-786e-4d19-cb7e-1fc1e8a98ef1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/57.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m51.2/57.6 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-15.0.0\n"
          ]
        }
      ],
      "source": [
        "pip install pytube"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install git+https://github.com/openai/whisper.git -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEuh12CQYcyi",
        "outputId": "8750d9ce-5547-4693-dea4-a6996da3600e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "import pytube"
      ],
      "metadata": {
        "id": "iqQXWexQYgBx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading the taken Youtube link\n",
        "url = \"https://www.youtube.com/watch?v=QDX-1M5Nj7s\"\n",
        "video = pytube.YouTube(url,use_oauth=False,\n",
        "        allow_oauth_cache=True)\n",
        "video.streams.get_highest_resolution().filesize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FUhWKz1Y0HB",
        "outputId": "a914ff91-7a98-48ba-b0d4-72e8572fbe18"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "93449491"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting and downloading as 'MP4' file\n",
        "audio = video.streams.get_audio_only()\n",
        "fn = audio.download(output_path=\"tmp.mp3\")"
      ],
      "metadata": {
        "id": "CAQzzx3VY6Mp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the 'base' model of Whisper\n",
        "model = whisper.load_model(\"base\")"
      ],
      "metadata": {
        "id": "q-fKBf3PaG4u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8c4328d-9128-4641-c5fa-5ef91ef382a4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 139M/139M [00:02<00:00, 63.4MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transcription = model.transcribe(\"/content/tmp.mp3/MIT Introduction to Deep Learning  6S191.mp4\")"
      ],
      "metadata": {
        "id": "YkKvgw6eZ5HW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = transcription['segments']\n",
        "print(res)"
      ],
      "metadata": {
        "id": "6_jyeEqJaRiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdlpSiqyfMxs",
        "outputId": "3f93125a-f9e9-4c9e-8b6c-b4ef409f9b3b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 2,\n",
              " 'seek': 0,\n",
              " 'start': 19.88,\n",
              " 'end': 26.16,\n",
              " 'text': ' super excited to introduce you all to introduction to deep learning. Now, MIT Inter to Deep',\n",
              " 'tokens': [51358,\n",
              "  1687,\n",
              "  2919,\n",
              "  281,\n",
              "  5366,\n",
              "  291,\n",
              "  439,\n",
              "  281,\n",
              "  9339,\n",
              "  281,\n",
              "  2452,\n",
              "  2539,\n",
              "  13,\n",
              "  823,\n",
              "  11,\n",
              "  13100,\n",
              "  5751,\n",
              "  281,\n",
              "  14895,\n",
              "  51672],\n",
              " 'temperature': 0.0,\n",
              " 'avg_logprob': -0.2659889050384066,\n",
              " 'compression_ratio': 1.4126984126984128,\n",
              " 'no_speech_prob': 0.10993754118680954}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "def store_segments(segments):\n",
        "  texts = []\n",
        "  start_times = []\n",
        "\n",
        "  for segment in segments:\n",
        "    text = segment['text']\n",
        "    start = segment['start']\n",
        "\n",
        "    # Convert the starting time to a datetime object\n",
        "    start_datetime = datetime.fromtimestamp(start)\n",
        "\n",
        "    # Format the starting time as a string in the format \"00:00:00\"\n",
        "    formatted_start_time = start_datetime.strftime('%H:%M:%S')\n",
        "\n",
        "    texts.append(\"\".join(text))\n",
        "    start_times.append(formatted_start_time)\n",
        "\n",
        "  return texts, start_times"
      ],
      "metadata": {
        "id": "G43zeNwUiSkv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_segments(res)"
      ],
      "metadata": {
        "id": "yaqzfco_iVOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts, start_times = store_segments(res)"
      ],
      "metadata": {
        "id": "-ZYECiqNgZ8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain"
      ],
      "metadata": {
        "id": "qBBaaahmqCWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai"
      ],
      "metadata": {
        "id": "DLAEaZSYqInM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install faiss-gpu"
      ],
      "metadata": {
        "id": "AbdW-kuUqM2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores.faiss import FAISS\n",
        "from langchain.chains import VectorDBQAWithSourcesChain\n",
        "from langchain import OpenAI\n",
        "import openai\n",
        "import faiss"
      ],
      "metadata": {
        "id": "lqQNXEvAqT62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\""
      ],
      "metadata": {
        "id": "vgN9CeSaqhUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = CharacterTextSplitter(chunk_size=1500, separator=\"\\n\")\n",
        "docs = []\n",
        "metadatas = []\n",
        "for i, d in enumerate(texts):\n",
        "    splits = text_splitter.split_text(d)\n",
        "    docs.extend(splits)\n",
        "    metadatas.extend([{\"source\": start_times[i]}] * len(splits))\n",
        "embeddings = OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "tjMXHVwRqqTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store = FAISS.from_texts(docs, embeddings, metadatas=metadatas)\n",
        "faiss.write_index(store.index, \"docs.index\")"
      ],
      "metadata": {
        "id": "iFri6vBTqutR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQAWithSourcesChain"
      ],
      "metadata": {
        "id": "bUOIpXCFYg_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = VectorDBQAWithSourcesChain.from_llm(llm=OpenAI(temperature=0.9), vectorstore=store)"
      ],
      "metadata": {
        "id": "dZObHNoxqx5A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "890b4648-f59c-468a-d7aa-a30224ff1ebe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/qa_with_sources/vector_db.py:67: UserWarning: `VectorDBQAWithSourcesChain` is deprecated - please use `from langchain.chains import RetrievalQAWithSourcesChain`\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = chain({\"question\": \"What is Backpropagation?\"})"
      ],
      "metadata": {
        "id": "j9i9whWUYlJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Answer: {result['answer']}  Sources: {result['sources']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tKd-k8aa_xZ",
        "outputId": "70718e65-e99c-466f-edc4-89f56e2fbcd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer:  Backpropagation is an algorithm used for training neural networks by propagating errors from the output back to the input.\n",
            "  Sources: 00:42:28, 00:43:02, 00:43:21\n"
          ]
        }
      ]
    }
  ]
}